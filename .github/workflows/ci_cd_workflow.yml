name: Process Customers Data
permissions:
  contents: write
  id-token: write
  pull-requests: write  # Added for PR comments
on:
  push:
    branches:
      - main
    paths:
      - '**.py'
  pull_request:
    branches:
      - main
    paths:
      - '**.py'
  workflow_dispatch:

env:
  TEST_EXECUTION_ENV: prod

jobs:
  test:
    name: 'Run Python Tests'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
        
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov allure-pytest boto3 awscli pytest-rerunfailures pandas numpy moto python-docx
        
      - name: Debug - Check test files
        run: |
          echo "=== Python files in root directory ==="
          find . -maxdepth 1 -name "*.py" -type f
          echo ""
          echo "=== Test files found ==="
          find . -name "test_*.py" -o -name "*_test.py"
          echo ""
          echo "=== Content of test files ==="
          for file in $(find . -name "test_*.py" -o -name "*_test.py"); do
            if [ -f "$file" ]; then
              echo "--- $file ---"
              head -10 "$file"
              echo ""
            fi
          done
          
      - name: Create directories for reports
        run: |
          mkdir -p allure-results
          mkdir -p coverage_html
          
      - name: Run Python tests with Allure
        id: run_tests
        continue-on-error: true
        run: |
          export PYTHONPATH=$PYTHONPATH:$GITHUB_WORKSPACE
          echo "=== Running pytest with Allure output ==="
          # Only run pytest on actual test files, not all Python files
          if find . -name "test_*.py" -o -name "*_test.py" | grep -q .; then
            pytest $(find . -name "test_*.py" -o -name "*_test.py") \
              --tb=long \
              -v \
              --cov=. \
              --cov-report=xml:coverage.xml \
              --cov-report=html:coverage_html \
              --alluredir=allure-results \
              --reruns=1 \
              --reruns-delay=1 || echo "Tests completed with errors"
          else
            echo "No test files found!"
            exit 1
          fi
          
      - name: Debug - Check allure-results directory
        if: always()
        run: |
          echo "Contents of allure-results:"
          ls -la allure-results/ || echo "No allure-results directory found"
          echo ""
          echo "Contents of coverage files:"
          ls -la coverage* || echo "No coverage files found"
      
      - name: Upload Coverage Report (XML)
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-xml
          path: coverage.xml
          retention-days: 30
      
      - name: Upload Coverage Report (HTML)
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-html
          path: coverage_html/
          retention-days: 30
      
      - name: Upload Allure Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: allure-results
          path: allure-results/
          retention-days: 30
      
      - name: Get Allure history
        uses: actions/checkout@v4
        if: always()
        continue-on-error: true
        with:
          ref: gh-pages
          path: gh-pages
      
      - name: Generate Allure Report
        uses: simple-elf/allure-report-action@master
        if: always()
        id: allure-report
        with:
          allure_results: allure-results
          gh_pages: gh-pages
          allure_report: allure-report
          allure_history: allure-history
          keep_reports: 20
      
      - name: Deploy report to Github Pages
        if: always()
        uses: peaceiris/actions-gh-pages@v3
        with:
          PERSONAL_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PUBLISH_BRANCH: gh-pages
          PUBLISH_DIR: allure-history
      
      - name: Upload Allure Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: allure-report
          path: allure-report/
          retention-days: 30
      
      - name: Set workflow metadata
        if: always()
        run: |
          echo "event_name=$GITHUB_EVENT_NAME" >> $GITHUB_OUTPUT
          echo "workflow=$GITHUB_WORKFLOW" >> $GITHUB_OUTPUT
          echo "actor=$GITHUB_ACTOR" >> $GITHUB_OUTPUT
          echo "run_number=$GITHUB_RUN_NUMBER" >> $GITHUB_OUTPUT
          echo "run_id=$GITHUB_RUN_ID" >> $GITHUB_OUTPUT
          echo "sha=$GITHUB_SHA" >> $GITHUB_OUTPUT
        id: metadata
      
      - name: Add Coverage Comment to PR
        if: github.event_name == 'pull_request' && always()
        uses: MishaKav/pytest-coverage-comment@main
        with:
          pytest-xml-coverage-path: coverage.xml
          title: Python Test Coverage Report
          badge-title: Coverage
          create-new-comment: true
          hide-badge: false
          hide-report: false
          report-only-changed-files: true
          remove-link-from-badge: false
          
      - name: Check test status and set job output
        if: always()
        id: check_status
        run: |
          if [ "${{ steps.run_tests.outcome }}" == "failure" ]; then
            echo "tests_failed=true" >> $GITHUB_OUTPUT
            echo "âŒ Tests failed"
          else
            echo "tests_failed=false" >> $GITHUB_OUTPUT
            echo "âœ… Tests passed"
          fi
          
      - name: Comment test results on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const testsFailed = '${{ steps.check_status.outputs.tests_failed }}' === 'true';
            const runNumber = '${{ steps.metadata.outputs.run_number }}';
            const runId = '${{ steps.metadata.outputs.run_id }}';
            const actor = '${{ steps.metadata.outputs.actor }}';
            const sha = '${{ steps.metadata.outputs.sha }}';
            
            const status = testsFailed ? 'âŒ Failed' : 'âœ… Passed';
            const emoji = testsFailed ? 'ğŸ”´' : 'ğŸŸ¢';
            
            const body = `## ${emoji} Test Results
            
            **Status:** ${status}
            **Triggered by:** @${actor}
            **Commit:** ${sha.substring(0, 7)}
            **Run:** [#${runNumber}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${runId})
            
            ${testsFailed ? 'âš ï¸ Some tests failed. Please check the detailed results above.' : 'ğŸ‰ All tests passed successfully!'}
            
            ğŸ“Š [View detailed coverage report](${{ github.server_url }}/${{ github.repository }}/actions/runs/${runId})
            ğŸ“ˆ [View Allure report](${{ github.server_url }}/${{ github.repository }}/actions/runs/${runId})
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
            
      - name: Fail job if tests failed
        if: steps.check_status.outputs.tests_failed == 'true'
        run: |
          echo "Tests failed, failing the job"
          exit 1
    
    outputs:
      tests_failed: ${{ steps.check_status.outputs.tests_failed }}
      coverage_report: ${{ steps.allure-report.outputs.report_url }}
      run_number: ${{ steps.metadata.outputs.run_number }}
      
  notify:
    name: 'Notify Results'
    runs-on: ubuntu-latest
    needs: test
    if: always()
    steps:
      - name: Notify Success
        if: needs.test.outputs.tests_failed == 'false'
        run: |
          echo "ğŸ‰ All tests passed successfully!"
          echo "Run number: ${{ needs.test.outputs.run_number }}"
          
      - name: Notify Failure
        if: needs.test.outputs.tests_failed == 'true'
        run: |
          echo "âŒ Tests failed in run ${{ needs.test.outputs.run_number }}"
          echo "Please check the test results and fix any issues."
          exit 1
