name: Process Customers Data

permissions:
  contents: write
  pages: write
  id-token: write

on:
  push:
    branches:
      - main
    paths:
      - '**.py'
  workflow_dispatch:

env:
  TEST_EXECUTION_ENV: prod

jobs:
  test:
    name: 'Run Python Tests'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
        
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov allure-pytest boto3 awscli pytest-rerunfailures pandas numpy moto python-docx
        
      - name: Debug - Check test files
        run: |
          echo "=== Python files in root directory ==="
          find . -maxdepth 1 -name "*.py" -type f
          echo ""
          echo "=== Test files found ==="
          find . -name "test_*.py" -o -name "*_test.py"
          echo ""
          echo "=== Content of test files ==="
          for file in test_*.py *_test.py; do
            if [ -f "$file" ]; then
              echo "--- $file ---"
              head -10 "$file"
              echo ""
            fi
          done
          
      - name: Run Python tests with Allure
        id: run_tests
        continue-on-error: true
        run: |
          export PYTHONPATH=$PYTHONPATH:$GITHUB_WORKSPACE
          echo "=== Running pytest with Allure output ==="
          pytest *.py test_*.py *_test.py --tb=long -v --cov=. --cov-report=xml:coverage.xml --cov-report=html:coverage_html --alluredir=allure-results || echo "Tests completed with errors"

      - name: Debug - Check allure-results directory
        if: always()
        run: |
          echo "Contents of allure-results:"
          ls -l allure-results || echo "No allure-results directory found"
      
      - name: Get Allure history
        uses: actions/checkout@v4
        if: always()
        continue-on-error: true
        with:
          ref: gh-pages
          path: gh-pages
      
      - name: Upload Coverage Report (HTML)
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage_html
          path: coverage_html
      
      - name: Upload Allure Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: allure-results
          path: allure-results
      
      - name: Generate Allure Report
        uses: simple-elf/allure-report-action@master
        if: always()
        with:
          allure_results: allure-results
          allure_history: allure-history
      
      - name: Upload Allure Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: allure-report
          path: allure-report
      
      - name: Deploy to GitHub Pages
        if: always()
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: allure-history
          keep_files: false
      
      - name: Set current date as env variable
        if: always()
        run: |
          echo "event_name=$GITHUB_EVENT_NAME" >> $GITHUB_OUTPUT
          echo "workflow=$GITHUB_WORKFLOW" >> $GITHUB_OUTPUT
          echo "actor=$GITHUB_ACTOR" >> $GITHUB_OUTPUT
          echo "run_number=$GITHUB_RUN_NUMBER" >> $GITHUB_OUTPUT
        id: version
      
      - name: Add Coverage Comment to PR
        if: github.event_name == 'pull_request' && always()
        uses: MishaKav/pytest-coverage-comment@main
        with:
          pytest-xml-coverage-path: coverage.xml
          title: Python Test Coverage Report
          create-new-comment: true
          report-only-changed-files: true
          
      - name: Check test status and set job output
        if: always()
        id: check_status
        run: |
          if [ "${{ steps.run_tests.outcome }}" == "failure" ]; then
            echo "tests_failed=true" >> $GITHUB_OUTPUT
          else
            echo "tests_failed=false" >> $GITHUB_OUTPUT
          fi
    outputs:
      tests_failed: ${{ steps.check_status.outputs.tests_failed }}
